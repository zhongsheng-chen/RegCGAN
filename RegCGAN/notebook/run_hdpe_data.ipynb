{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/zhongsheng/anaconda2/envs/ganRegression/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<module 'models.cgan_model' from '/Users/zhongsheng/Documents/GitWorkspace/ganRegression/models/cgan_model.py'>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import dataset, metrics, plotting, config, network\n",
    "from models import cgan_model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "importlib.reload(network)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(config)\n",
    "importlib.reload(cgan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../figures/hdpe already exists replacing files in this notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_config = config.DatasetConfig(scenario=\"hdpe\")\n",
    "\n",
    "assert(dataset_config.scenario == \"magical_sinus\"\n",
    "      or dataset_config.scenario == \"hdpe\")\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_config = config.Config(\n",
    "    model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0001,\n",
    "                             optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=5),\n",
    "    training=config.TrainingConfig(n_epochs=10000, batch_size=100, n_samples=500),\n",
    "    dataset=dataset_config,\n",
    "    run=config.RunConfig(save_fig=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(exp_config.model.random_seed)\n",
    "random.seed(exp_config.model.random_seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = dataset.get_dataset(scenario=exp_config.dataset.scenario,\n",
    "                                                                         seed=exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%% max-min nomalization, which is a prerequisite in compution of unanchored_L2_discrepancy.\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding sparse regions using Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "X = X_train_scaled\n",
    "clf = LocalOutlierFactor(n_neighbors=40)\n",
    "clf.fit(X)\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "mean_scores = np.mean(X_scores)\n",
    "mask = X_scores > mean_scores\n",
    "\n",
    "X_outliers = X[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVT sampling and discrepancy evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from idaes.surrogate.pysmo import sampling as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from diversipy import unanchored_L2_discrepancy\n",
    "\n",
    "assert len(X_outliers) !=0, \"No sparse regions in the input space has been found.\"\n",
    "\n",
    "min_n_sampling, max_n_sampling, interval = 60, 500, 60\n",
    "\n",
    "minimum, maximum = np.amin(X_outliers, axis=0).tolist(), np.amax(X_outliers, axis=0).tolist()\n",
    "bounds = [minimum, maximum]\n",
    "\n",
    "X_discrepancy = unanchored_L2_discrepancy(X_outliers)\n",
    "X_CVT_discrepancy_list, X_full_discrepancy_list, CVT_dict = [], [], {}\n",
    "i = 0\n",
    "for n_sampling in range(min_n_sampling, max_n_sampling, interval):\n",
    "    space_init = sp.CVTSampling(bounds, sampling_type=\"creation\", number_of_samples=n_sampling)\n",
    "    X_CVT = space_init.sample_points()\n",
    "    CVT_dict[f\"num_sampling_{n_sampling}\"] = X_CVT\n",
    "    X_CVT_discrepancy = unanchored_L2_discrepancy(X_CVT)\n",
    "    X_CVT_discrepancy_list.append(X_CVT_discrepancy)\n",
    "\n",
    "    X_full = np.r_[X, X_CVT]\n",
    "    X_full_discrepancy = unanchored_L2_discrepancy(X_full)\n",
    "    X_full_discrepancy_list.append(X_full_discrepancy)\n",
    "    print(f\"Discrepancy values: {X_discrepancy:.2e} for original data; \"\n",
    "          f\"{X_CVT_discrepancy:.2e} for {n_sampling} CVT samples; \"\n",
    "          f\"{X_full_discrepancy:.2e} for full data.\")\n",
    "\n",
    "best_n_sampling = np.arange(min_n_sampling, max_n_sampling, interval)[np.argmin(np.array(X_full_discrepancy_list))]\n",
    "best_CVT = CVT_dict[f\"num_sampling_{best_n_sampling}\"]\n",
    "print(f\"The  optimal value for n_sampling in CVT sampling is {best_n_sampling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%  explore the optimal value for n_sampling\n"
    }
   },
   "outputs": [],
   "source": [
    "X_discrepancy = unanchored_L2_discrepancy(X_outliers)\n",
    "plotting.plot_cvt_discrepancy(min_n_sampling, max_n_sampling, interval,\n",
    "                              X_full_discrepancy_list, fig_dir,\n",
    "                              title=f\"Discrepancy baseline = {X_discrepancy:2.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Plot Voronoi tessellation digram for CVT samples the size of best_n_sampling.\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import voronoi_plot_2d\n",
    "\n",
    "sampling_key = f\"num_sampling_{best_n_sampling}\"\n",
    "X_CVT = CVT_dict[sampling_key]\n",
    "\n",
    "# save CVT samples to .npy file\n",
    "from os.path import basename\n",
    "np.save(f\"{fig_dir}/{basename(fig_dir)}_CVT_samples.npy\", X_scaler.inverse_transform(X_CVT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%% z-score nomalization\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_valid_scaled = X_scaler.transform(X_valid)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_valid_scaled = y_scaler.transform(y_valid.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "\n",
    "variance = 1\n",
    "length = 80\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=15, variance=variance, lengthscale=length)\n",
    "gpr = GPy.models.GPRegression(X_train_scaled, y_train_scaled, kernel)\n",
    "\n",
    "run_hyperopt_search = False\n",
    "if run_hyperopt_search:\n",
    "    gpr.optimize(messages=True)\n",
    "ypred_gp_val, cov = gpr.predict(X_valid_scaled)\n",
    "plotting.plot_densities_joint(y_valid, None, None, y_scaler.inverse_transform(ypred_gp_val),\n",
    "                             title=f\"Marginalized $P(y)$\", fig_dir=fig_dir,\n",
    "                             prefix=\"marginalized_P(y)\", save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cgan = cgan_model.CGAN(exp_config)\n",
    "d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = cgan.train(X_train_scaled, y_train_scaled,\n",
    "                                                                              epochs=exp_config.training.n_epochs,\n",
    "                                                                              batch_size=exp_config.training.batch_size,\n",
    "                                                                              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plots(d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true, fig_dir, exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ypred_single_cgan_val = cgan.predict(X_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ypred_mean_cgan_val, _, _ = cgan.sample(X_valid_scaled, exp_config.training.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% using inverse normalization to transform the output to its true field\n"
    }
   },
   "outputs": [],
   "source": [
    "ypred_gp_val = y_scaler.inverse_transform(ypred_gp_val)\n",
    "ypred_single_cgan_val = y_scaler.inverse_transform(ypred_single_cgan_val)\n",
    "ypred_mean_cgan_val = y_scaler.inverse_transform(ypred_mean_cgan_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_densities_joint(y_valid, ypred_single_cgan_val, ypred_mean_cgan_val, ypred_gp_val,\n",
    "                             title=f\"Marginalized $P(y)$\", fig_dir=fig_dir,\n",
    "                             prefix=\"marginalized_P(y)\", save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_ypred_error(y_valid, ypred_single_cgan_val, ypred_mean_cgan_val, ypred_gp_val,\n",
    "                          fig_dir=fig_dir, prefix=\"single_mean_cgan_gp\", save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metrics on validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "single_cgan_mae_list = []\n",
    "single_cgan_mse_list= []\n",
    "\n",
    "mean_cgan_mae_list = []\n",
    "mean_cgan_mse_list = []\n",
    "\n",
    "gp_mae_list = []\n",
    "gp_mse_list =[]\n",
    "\n",
    "n_eval_runs = 50\n",
    "for i in range(n_eval_runs):\n",
    "    ypred_single_cgan = cgan.predict(X_valid_scaled)\n",
    "    single_cgan_mae_list.append(mean_absolute_error(y_valid, y_scaler.inverse_transform(ypred_single_cgan)))\n",
    "    single_cgan_mse_list.append(mean_squared_error(y_valid, y_scaler.inverse_transform(ypred_single_cgan)))\n",
    "\n",
    "    ypred_mean_cgan, _, _ = cgan.sample(X_valid_scaled, exp_config.training.n_samples)\n",
    "    mean_cgan_mae_list.append(mean_absolute_error(y_valid, y_scaler.inverse_transform(ypred_mean_cgan)))\n",
    "    mean_cgan_mse_list.append(mean_squared_error(y_valid, y_scaler.inverse_transform(ypred_mean_cgan)))\n",
    "\n",
    "    y_pred_gp, cov = gpr.predict(X_valid_scaled)\n",
    "    yped_gp = np.random.normal(y_pred_gp, np.sqrt(cov))\n",
    "    gp_mae_list.append(mean_absolute_error(y_valid, y_scaler.inverse_transform(yped_gp)))\n",
    "    gp_mse_list.append(mean_squared_error(y_valid, y_scaler.inverse_transform(yped_gp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "single_cgan_mae_mean, single_cgan_mae_std = np.mean(np.asarray(single_cgan_mae_list)), np.std(np.asarray(single_cgan_mae_list))\n",
    "single_cgan_mse_mean, single_cgan_mse_std = np.mean(np.asarray(single_cgan_mse_list)), np.std(np.asarray(single_cgan_mse_list))\n",
    "\n",
    "print(f\"Single CGAN validation MAE: {single_cgan_mae_mean:.3e} +- {single_cgan_mae_std:.5e}\")\n",
    "print(f\"Single CGAN validation MSE: {single_cgan_mse_mean:.3e} +- {single_cgan_mse_std:.5e}\")\n",
    "\n",
    "mean_cgan_mae_mean, mean_cgan_mae_std = np.mean(np.asarray(mean_cgan_mae_list)), np.std(np.asarray(mean_cgan_mae_list))\n",
    "mean_cgan_mse_mean, mean_cgan_mse_std = np.mean(np.asarray(mean_cgan_mse_list)), np.std(np.asarray(mean_cgan_mse_list))\n",
    "\n",
    "print(f\"Mean CGAN validation MAE: {mean_cgan_mae_mean:.3e} +- {mean_cgan_mae_std:.5e}\")\n",
    "print(f\"Mean CGAN validation MSE: {mean_cgan_mse_mean:.3e} +- {mean_cgan_mse_std:.5e}\")\n",
    "\n",
    "gp_mae_mean, gp_mae_std = np.mean(np.asarray(gp_mae_list)), np.std(np.asarray(gp_mae_list))\n",
    "gp_mse_mean, gp_mse_std = np.mean(np.asarray(gp_mse_list)), np.std(np.asarray(gp_mse_list))\n",
    "print(f\"GP validation MAE: {gp_mae_mean:.3e} +- {gp_mae_std:.5e}\")\n",
    "print(f\"GP validation MSE: {gp_mse_mean:.3e} +- {gp_mse_std:.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlpd_list = []\n",
    "for i in range(n_eval_runs):\n",
    "    y_pred_gp, cov = gpr.predict(X_valid_scaled)\n",
    "    nlpd_list.append(metrics.gaussian_NLPD(y_valid,\n",
    "                                           np.random.normal(y_scaler.inverse_transform(ypred_gp_val), np.sqrt(cov)),\n",
    "                                           cov))\n",
    "gp_nlpd_mean = np.mean(nlpd_list)\n",
    "gp_nlpd_std = np.std(nlpd_list)\n",
    "print(f\"GP validation NLPD: {gp_nlpd_mean:.3f} +- {gp_nlpd_std:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlpd_list = []\n",
    "for i in range(n_eval_runs):\n",
    "    ypred_single_cgan = cgan.predict(X_valid_scaled)\n",
    "    cov = np.ones(len(ypred_single_cgan))* np.mean((y_valid - y_scaler.inverse_transform(ypred_single_cgan))**2)\n",
    "    nlpd_list.append(metrics.gaussian_NLPD(y_valid, y_scaler.inverse_transform(ypred_single_cgan), cov))\n",
    "single_cgan_nlpd_mean = np.mean(nlpd_list)\n",
    "single_cgan_nlpd_std = np.std(nlpd_list)\n",
    "print(f\"Single CGAN Validation NLPD: {single_cgan_nlpd_mean:.3f} +- {single_cgan_nlpd_std:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, w, _ = metrics.Parzen(cgan, X_valid_scaled, y_valid_scaled)\n",
    "nlpd_list = []\n",
    "for i in range(n_eval_runs):\n",
    "    nlpd_list.append(metrics.Parzen_test(cgan, X_valid_scaled, y_valid_scaled, 0.01, exp_config.training.n_samples))\n",
    "mean_cgan_nlpd_mean = np.mean(nlpd_list)\n",
    "mean_cgan_nlpd_std = np.std(nlpd_list)\n",
    "print(f\"Mean CGAN Validation NLPD: {mean_cgan_nlpd_mean:.3f} +- {mean_cgan_nlpd_std:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if exp_config.run.save_fig:\n",
    "\n",
    "    try:\n",
    "        file = open(f\"{fig_dir}/metrics_on_hdpe.txt\",\"w\")\n",
    "    except FileExistsError:\n",
    "        print(f\" {fig_dir} was failed to create.\")\n",
    "\n",
    "    file.write(f\"===Validation MAE===\\n\")\n",
    "    file.write(f\"GP validation MAE: {gp_mae_mean} +- {gp_mae_std}\\n\")\n",
    "    file.write(f\"Single CGAN validation MAE: {single_cgan_mae_mean} +- {single_cgan_mae_std}\\n\")\n",
    "    file.write(f\"Mean CGAN validation MAE: {mean_cgan_mae_mean} +- {mean_cgan_mae_std}\\n\")\n",
    "    file.write(f\"===Validation MSE===\\n\")\n",
    "    file.write(f\"GP validation MSE: {gp_mse_mean} +- {gp_mse_std}\\n\")\n",
    "    file.write(f\"Single CGAN validation MSE: {single_cgan_mse_mean} +- {single_cgan_mse_std}\\n\")\n",
    "    file.write(f\"CGAN validation MSE: {mean_cgan_mse_mean} +- {mean_cgan_mse_std}\\n\")\n",
    "    file.write(f\"===Validation NLPD===\\n\")\n",
    "    file.write(f\"GP Gaussian NLPD: {gp_nlpd_mean} +- {gp_nlpd_std}\\n\")\n",
    "    file.write(f\"Single CGAN NLPD: {single_cgan_nlpd_mean} +- {single_cgan_nlpd_std}\\n\")\n",
    "    file.write(f\"Mean CGAN NLPD: {mean_cgan_nlpd_mean} +- {mean_cgan_nlpd_std}\\n\")\n",
    "    file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ganRegression)",
   "language": "python",
   "name": "pycharm-25d74700"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}