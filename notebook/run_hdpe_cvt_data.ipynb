{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.reg_cgan_model' from '/Users/zhongsheng/Documents/GitWorkspace/RegCGAN/models/reg_cgan_model.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since the output of at any CVT points for HDPE is not available,\n",
    "we will not carry out evaluating metrics on the generated virtual samples,\n",
    "as the way that have done for magical_sinus benchmarking dataset. Instead,\n",
    "we indirectly confirm the quality of the generated samples by showing the\n",
    "ability of our RegCGAN on capturing P(y|x).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import dataset, metrics, plotting, config, network\n",
    "from models import reg_cgan_model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "importlib.reload(network)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(config)\n",
    "importlib.reload(reg_cgan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../figures/hdpeuce already exists replacing files in this notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_config = config.DatasetConfig(scenario=\"hdpeuce\")\n",
    "\n",
    "assert(dataset_config.scenario == \"magical_sinus\"\n",
    "      or dataset_config.scenario == \"hdpeuce\")\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_config = config.Config(\n",
    "    model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0001,\n",
    "                             optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=5),\n",
    "    training=config.TrainingConfig(n_epochs=10000, batch_size=100, n_sampling=200),\n",
    "    dataset=dataset_config,\n",
    "    run=config.RunConfig(save_fig=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(exp_config.model.random_seed)\n",
    "random.seed(exp_config.model.random_seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = dataset.get_dataset(scenario=exp_config.dataset.scenario,\n",
    "                                                                         seed=exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%% z-score nomalization\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_valid_scaled = X_scaler.fit_transform(X_valid)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_valid_scaled = y_scaler.fit_transform(y_valid.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60099b17190e4aa8ac7287fa1a45ecca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import GPy\n",
    "\n",
    "variance = 0.1\n",
    "length = 1\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=15, variance=variance, lengthscale=length)\n",
    "gpr = GPy.models.GPRegression(X_train_scaled, y_train_scaled, kernel)\n",
    "\n",
    "run_hyperopt_search = True\n",
    "if run_hyperopt_search:\n",
    "    gpr.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct CGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Generator_input_x (InputLayer)  (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Generator_input_z (InputLayer)  (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 60)           960         Generator_input_x[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 60)           360         Generator_input_z[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120)          0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          14520       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 120)          14520       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 120)          14520       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 120)          14520       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            121         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 59,521\n",
      "Trainable params: 59,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Discriminator_input_x (InputLay (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Discriminator_input_y (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 60)           960         Discriminator_input_x[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 60)           120         Discriminator_input_y[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 120)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          14520       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          14520       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 120)          14520       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          14520       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            121         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,562\n",
      "Trainable params: 59,281\n",
      "Non-trainable params: 59,281\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/zhongsheng/anaconda2/envs/Reg-CGAN/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / dLoss: 12.228018760681152 / gLoss: 0.28676560521125793\n",
      "Epoch: 1 / dLoss: 13.788334846496582 / gLoss: 0.01779765449464321\n",
      "Epoch: 2 / dLoss: 9.354936599731445 / gLoss: 1.345212459564209\n",
      "Epoch: 3 / dLoss: 0.0019480367191135883 / gLoss: 14.967238426208496\n",
      "Epoch: 4 / dLoss: 0.0021685969550162554 / gLoss: 15.802855491638184\n",
      "Epoch: 5 / dLoss: 0.007570695132017136 / gLoss: 15.96017074584961\n",
      "Epoch: 6 / dLoss: 0.019252179190516472 / gLoss: 16.118101119995117\n",
      "Epoch: 7 / dLoss: 0.03875555843114853 / gLoss: 16.107845306396484\n",
      "Epoch: 8 / dLoss: 0.13578028976917267 / gLoss: 16.118101119995117\n",
      "Epoch: 9 / dLoss: 0.1393631547689438 / gLoss: 16.118101119995117\n",
      "Epoch: 10 / dLoss: 0.1544414460659027 / gLoss: 16.118101119995117\n",
      "Epoch: 11 / dLoss: 0.1897730529308319 / gLoss: 16.118101119995117\n",
      "Epoch: 12 / dLoss: 0.19185158610343933 / gLoss: 16.118101119995117\n",
      "Epoch: 13 / dLoss: 0.06096334010362625 / gLoss: 16.118101119995117\n",
      "Epoch: 14 / dLoss: 0.07821130007505417 / gLoss: 16.118101119995117\n",
      "Epoch: 15 / dLoss: 0.021199865266680717 / gLoss: 16.118101119995117\n",
      "Epoch: 16 / dLoss: 0.021317951381206512 / gLoss: 16.118101119995117\n",
      "Epoch: 17 / dLoss: 0.010635041631758213 / gLoss: 16.118101119995117\n",
      "Epoch: 18 / dLoss: 0.003222601255401969 / gLoss: 16.118101119995117\n",
      "Epoch: 19 / dLoss: 0.002225816948339343 / gLoss: 16.118101119995117\n",
      "Epoch: 20 / dLoss: 0.0005200238083489239 / gLoss: 16.118101119995117\n",
      "Epoch: 21 / dLoss: 0.0010432401904836297 / gLoss: 16.118101119995117\n",
      "Epoch: 22 / dLoss: 0.001654582447372377 / gLoss: 16.118101119995117\n",
      "Epoch: 23 / dLoss: 0.0010065886890515685 / gLoss: 16.118101119995117\n",
      "Epoch: 24 / dLoss: 0.0005164552130736411 / gLoss: 16.118101119995117\n",
      "Epoch: 25 / dLoss: 0.0005085357697680593 / gLoss: 16.118101119995117\n",
      "Epoch: 26 / dLoss: 0.0003561542253009975 / gLoss: 16.118101119995117\n",
      "Epoch: 27 / dLoss: 0.00045547791523858905 / gLoss: 16.118101119995117\n",
      "Epoch: 28 / dLoss: 0.0005340095958672464 / gLoss: 16.118101119995117\n",
      "Epoch: 29 / dLoss: 0.00013799042790196836 / gLoss: 16.118101119995117\n",
      "Epoch: 30 / dLoss: 5.306605089572258e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 31 / dLoss: 0.00015559613530058414 / gLoss: 16.118101119995117\n",
      "Epoch: 32 / dLoss: 0.00011799206549767405 / gLoss: 16.118101119995117\n",
      "Epoch: 33 / dLoss: 0.00036839820677414536 / gLoss: 16.118101119995117\n",
      "Epoch: 34 / dLoss: 0.00019739495473913848 / gLoss: 16.118101119995117\n",
      "Epoch: 35 / dLoss: 5.250540925771929e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 36 / dLoss: 9.02299416338792e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 37 / dLoss: 0.0001254723028978333 / gLoss: 16.118101119995117\n",
      "Epoch: 38 / dLoss: 6.18019257672131e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 39 / dLoss: 6.7076643972541206e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 40 / dLoss: 0.00014209802611730993 / gLoss: 16.118101119995117\n",
      "Epoch: 41 / dLoss: 0.00010321675654267892 / gLoss: 16.118101119995117\n",
      "Epoch: 42 / dLoss: 0.00013253389624878764 / gLoss: 16.118101119995117\n",
      "Epoch: 43 / dLoss: 4.9822112487163395e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 44 / dLoss: 6.001976362313144e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 45 / dLoss: 1.9182094547431916e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 46 / dLoss: 0.00020314396533649415 / gLoss: 16.118101119995117\n",
      "Epoch: 47 / dLoss: 0.00014034252671990544 / gLoss: 16.118101119995117\n",
      "Epoch: 48 / dLoss: 0.00032818387262523174 / gLoss: 16.118101119995117\n",
      "Epoch: 49 / dLoss: 0.00013813776604365557 / gLoss: 16.118101119995117\n",
      "Epoch: 50 / dLoss: 0.0002407882857369259 / gLoss: 16.118101119995117\n",
      "Epoch: 51 / dLoss: 8.728220564080402e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 52 / dLoss: 1.1604794963204768e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 53 / dLoss: 2.0345616576378234e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 54 / dLoss: 0.0004314561083447188 / gLoss: 16.118101119995117\n",
      "Epoch: 55 / dLoss: 4.9242818931816146e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 56 / dLoss: 0.00018797814846038818 / gLoss: 16.118101119995117\n",
      "Epoch: 57 / dLoss: 3.4642518585314974e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 58 / dLoss: 0.00015785785217303783 / gLoss: 16.118101119995117\n",
      "Epoch: 59 / dLoss: 0.00013692355423700064 / gLoss: 16.118101119995117\n",
      "Epoch: 60 / dLoss: 0.0002117290860041976 / gLoss: 16.118101119995117\n",
      "Epoch: 61 / dLoss: 6.809813203290105e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 62 / dLoss: 0.0001448366674594581 / gLoss: 16.118101119995117\n",
      "Epoch: 63 / dLoss: 5.699078974430449e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 64 / dLoss: 6.494876288343221e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 65 / dLoss: 0.00011645569611573592 / gLoss: 16.118101119995117\n",
      "Epoch: 66 / dLoss: 7.76673732616473e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 67 / dLoss: 6.441340519813821e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 68 / dLoss: 0.00012294863699935377 / gLoss: 16.118101119995117\n",
      "Epoch: 69 / dLoss: 9.733832121128216e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 70 / dLoss: 6.415173265850171e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 71 / dLoss: 0.00011313162394799292 / gLoss: 16.118101119995117\n",
      "Epoch: 72 / dLoss: 0.00011900108074769378 / gLoss: 16.118101119995117\n",
      "Epoch: 73 / dLoss: 0.0001571557077113539 / gLoss: 16.118101119995117\n",
      "Epoch: 74 / dLoss: 1.0595232197374571e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 75 / dLoss: 0.0001412046840414405 / gLoss: 16.118101119995117\n",
      "Epoch: 76 / dLoss: 9.159644832834601e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 77 / dLoss: 2.9667397029697895e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 78 / dLoss: 0.0001205110311275348 / gLoss: 16.118101119995117\n",
      "Epoch: 79 / dLoss: 0.0001282956072827801 / gLoss: 16.118101119995117\n",
      "Epoch: 80 / dLoss: 4.629420072888024e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 81 / dLoss: 0.00018366320000495762 / gLoss: 16.118101119995117\n",
      "Epoch: 82 / dLoss: 0.00011630351946223527 / gLoss: 16.118101119995117\n",
      "Epoch: 83 / dLoss: 8.222920587286353e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 84 / dLoss: 1.9121602235827595e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 85 / dLoss: 9.730101010063663e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 86 / dLoss: 2.006476825044956e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 87 / dLoss: 5.011316534364596e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 88 / dLoss: 9.63568891165778e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 89 / dLoss: 0.00015804526628926396 / gLoss: 16.118101119995117\n",
      "Epoch: 90 / dLoss: 0.0001509683788754046 / gLoss: 16.118101119995117\n",
      "Epoch: 91 / dLoss: 0.00018190682749263942 / gLoss: 16.118101119995117\n",
      "Epoch: 92 / dLoss: 0.00013553205644711852 / gLoss: 16.118101119995117\n",
      "Epoch: 93 / dLoss: 0.000220833026105538 / gLoss: 16.118101119995117\n",
      "Epoch: 94 / dLoss: 3.700209708767943e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 95 / dLoss: 5.107132164994255e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 96 / dLoss: 7.814381388016045e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 97 / dLoss: 0.00012540498573798686 / gLoss: 16.118101119995117\n",
      "Epoch: 98 / dLoss: 0.00015975304995663464 / gLoss: 16.118101119995117\n",
      "Epoch: 99 / dLoss: 0.00010467315587447956 / gLoss: 16.118101119995117\n",
      "Epoch: 100 / dLoss: 6.907774513820186e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 101 / dLoss: 3.304701021988876e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 102 / dLoss: 0.00011109055776614696 / gLoss: 16.118101119995117\n",
      "Epoch: 103 / dLoss: 6.287825090112165e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 104 / dLoss: 4.400048783281818e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 105 / dLoss: 0.0001948896242538467 / gLoss: 16.118101119995117\n",
      "Epoch: 106 / dLoss: 0.0001111783494707197 / gLoss: 16.118101119995117\n",
      "Epoch: 107 / dLoss: 0.0002662701590452343 / gLoss: 16.118101119995117\n",
      "Epoch: 108 / dLoss: 8.692145456734579e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 109 / dLoss: 7.4126528488704935e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 110 / dLoss: 0.00015271565644070506 / gLoss: 16.118101119995117\n",
      "Epoch: 111 / dLoss: 8.306488598464057e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 112 / dLoss: 2.4792047042865306e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 113 / dLoss: 9.334993956144899e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 114 / dLoss: 8.407468703808263e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 115 / dLoss: 4.406259904499166e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 116 / dLoss: 1.428347695764387e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 117 / dLoss: 0.00013213457714300603 / gLoss: 16.118101119995117\n",
      "Epoch: 118 / dLoss: 0.00015365642320830375 / gLoss: 16.118101119995117\n",
      "Epoch: 119 / dLoss: 0.00019059386977460235 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 / dLoss: 4.054375494888518e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 121 / dLoss: 8.47651608637534e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 122 / dLoss: 8.021126996027306e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 123 / dLoss: 8.012338366825134e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 124 / dLoss: 1.3690977539226878e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 125 / dLoss: 2.5149642169708386e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 126 / dLoss: 3.1593932362739e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 127 / dLoss: 4.960812293575145e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 128 / dLoss: 5.778201375505887e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 129 / dLoss: 0.00014389862190000713 / gLoss: 16.118101119995117\n",
      "Epoch: 130 / dLoss: 1.2983578017156105e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 131 / dLoss: 5.105144009576179e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 132 / dLoss: 0.0001809168024919927 / gLoss: 16.118101119995117\n",
      "Epoch: 133 / dLoss: 9.366601443616673e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 134 / dLoss: 9.257309284294024e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 135 / dLoss: 4.3017411371693015e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 136 / dLoss: 3.0446833989117295e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 137 / dLoss: 6.907172064529732e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 138 / dLoss: 3.964793722843751e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 139 / dLoss: 7.374968117801473e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 140 / dLoss: 7.688252662774175e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 141 / dLoss: 5.102222530695144e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 142 / dLoss: 8.484534191666171e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 143 / dLoss: 2.6738578526419587e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 144 / dLoss: 1.7114560250774957e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 145 / dLoss: 8.179194992408156e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 146 / dLoss: 8.847016579238698e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 147 / dLoss: 6.528068479383364e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 148 / dLoss: 9.828383917920291e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 149 / dLoss: 0.0001001588098006323 / gLoss: 16.118101119995117\n",
      "Epoch: 150 / dLoss: 4.776777586812386e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 151 / dLoss: 9.484474139753729e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 152 / dLoss: 8.084338332992047e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 153 / dLoss: 0.00010702212603064254 / gLoss: 16.118101119995117\n",
      "Epoch: 154 / dLoss: 7.12320688762702e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 155 / dLoss: 9.684998804004863e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 156 / dLoss: 7.687514880672097e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 157 / dLoss: 7.030380220385268e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 158 / dLoss: 3.371746061020531e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 159 / dLoss: 0.0001040073620970361 / gLoss: 16.118101119995117\n",
      "Epoch: 160 / dLoss: 0.0001483543892391026 / gLoss: 16.118101119995117\n",
      "Epoch: 161 / dLoss: 0.00016191366012208164 / gLoss: 16.118101119995117\n",
      "Epoch: 162 / dLoss: 7.26761863916181e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 163 / dLoss: 4.2555842810543254e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 164 / dLoss: 2.5434217604924925e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 165 / dLoss: 5.343063094187528e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 166 / dLoss: 0.0001008324179565534 / gLoss: 16.118101119995117\n",
      "Epoch: 167 / dLoss: 6.833507359260693e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 168 / dLoss: 9.46887448662892e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 169 / dLoss: 5.77475548197981e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 170 / dLoss: 7.205624569905922e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 171 / dLoss: 0.00011371649452485144 / gLoss: 16.118101119995117\n",
      "Epoch: 172 / dLoss: 9.069417865248397e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 173 / dLoss: 2.612271418911405e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 174 / dLoss: 5.042616521677701e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 175 / dLoss: 2.126639174093725e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 176 / dLoss: 3.832803849945776e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 177 / dLoss: 4.095345866517164e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 178 / dLoss: 3.922687756130472e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 179 / dLoss: 1.2338411579548847e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 180 / dLoss: 8.180941949831322e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 181 / dLoss: 6.869476055726409e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 182 / dLoss: 1.4911963262420613e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 183 / dLoss: 1.5788105883984827e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 184 / dLoss: 1.299725681747077e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 185 / dLoss: 4.276477557141334e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 186 / dLoss: 2.7766249331762083e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 187 / dLoss: 7.535980694228783e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 188 / dLoss: 5.929709004703909e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 189 / dLoss: 3.432030644034967e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 190 / dLoss: 4.605770664056763e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 191 / dLoss: 0.0001028552433126606 / gLoss: 16.118101119995117\n",
      "Epoch: 192 / dLoss: 1.6129793948493898e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 193 / dLoss: 1.2322801012487616e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 194 / dLoss: 1.8232396541861817e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 195 / dLoss: 8.388185051444452e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 196 / dLoss: 4.6757078962400556e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 197 / dLoss: 5.547663749894127e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 198 / dLoss: 1.8286222257302143e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 199 / dLoss: 8.187505954992957e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 200 / dLoss: 3.0158204026520252e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 201 / dLoss: 9.979022252082359e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 202 / dLoss: 4.79040954814991e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 203 / dLoss: 1.0571825441729743e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 204 / dLoss: 4.793013431481086e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 205 / dLoss: 6.063578894099919e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 206 / dLoss: 5.877734656678513e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 207 / dLoss: 4.346309287939221e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 208 / dLoss: 1.6902899915294256e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 209 / dLoss: 3.348583049955778e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 210 / dLoss: 4.5179156586527824e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 211 / dLoss: 1.3808202311338391e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 212 / dLoss: 4.258537228452042e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 213 / dLoss: 2.719171425269451e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 214 / dLoss: 5.71896271139849e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 215 / dLoss: 2.7973273972747847e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 216 / dLoss: 2.0449964722502045e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 217 / dLoss: 3.8996640796540305e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 218 / dLoss: 2.2397951397579163e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 219 / dLoss: 1.11003882921068e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 220 / dLoss: 1.785586391633842e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 221 / dLoss: 6.926085461600451e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 222 / dLoss: 3.5329387173987925e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 223 / dLoss: 6.047807801223826e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 224 / dLoss: 2.0511437469394878e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 225 / dLoss: 1.806592808861751e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 226 / dLoss: 7.063039447530173e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 227 / dLoss: 1.1395365618227515e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 228 / dLoss: 7.374282176897395e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 229 / dLoss: 6.364892669807887e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 230 / dLoss: 2.352292176510673e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 231 / dLoss: 2.20853034988977e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 232 / dLoss: 1.877368958957959e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 233 / dLoss: 2.2208294467418455e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 234 / dLoss: 7.3524056460883e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 235 / dLoss: 1.532930946268607e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 236 / dLoss: 2.116265386575833e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 237 / dLoss: 1.0316042789781932e-05 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 238 / dLoss: 1.5037245248095132e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 239 / dLoss: 6.66470123178442e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 240 / dLoss: 2.7140202291775495e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 241 / dLoss: 8.948137292463798e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 242 / dLoss: 3.724915222846903e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 243 / dLoss: 1.9643995983642526e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 244 / dLoss: 1.1353103218425531e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 245 / dLoss: 8.364590030396357e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 246 / dLoss: 8.719669494894333e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 247 / dLoss: 2.717143070185557e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 248 / dLoss: 4.7795842874620575e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 249 / dLoss: 7.540217211499112e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 250 / dLoss: 1.4824593563389499e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 251 / dLoss: 1.2833375876653008e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 252 / dLoss: 1.1451513273641467e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 253 / dLoss: 1.730495750962291e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 254 / dLoss: 1.2734065421682317e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 255 / dLoss: 1.6332647646777332e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 256 / dLoss: 1.2506953680713195e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 257 / dLoss: 1.855417576734908e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 258 / dLoss: 1.172811880678637e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 259 / dLoss: 2.6491019525565207e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 260 / dLoss: 6.6930251705343835e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 261 / dLoss: 1.9639450329123065e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 262 / dLoss: 3.821456630248576e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 263 / dLoss: 1.7539787222631276e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 264 / dLoss: 1.2834236258640885e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 265 / dLoss: 1.2456504919100553e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 266 / dLoss: 1.3922432117396966e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 267 / dLoss: 6.643357664870564e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 268 / dLoss: 1.5458981579286046e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 269 / dLoss: 2.215409949712921e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 270 / dLoss: 4.5405312221191707e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 271 / dLoss: 1.2355447324807756e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 272 / dLoss: 1.4093012396187987e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 273 / dLoss: 6.489011866506189e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 274 / dLoss: 3.847640982712619e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 275 / dLoss: 8.279728717752732e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 276 / dLoss: 6.717955784552032e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 277 / dLoss: 1.369295296171913e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 278 / dLoss: 3.470915999059798e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 279 / dLoss: 1.1192456668140949e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 280 / dLoss: 1.2489891560107935e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 281 / dLoss: 1.0529231985856313e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 282 / dLoss: 1.5785753930686042e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 283 / dLoss: 1.8513288523536175e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 284 / dLoss: 7.2018942773866e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 285 / dLoss: 1.0690584531403147e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 286 / dLoss: 1.3904898878536187e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 287 / dLoss: 1.4107702554611024e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 288 / dLoss: 1.5023030755401123e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 289 / dLoss: 8.557715773349628e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 290 / dLoss: 1.0803703844430856e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 291 / dLoss: 1.678213448030874e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 292 / dLoss: 6.964757176319836e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 293 / dLoss: 5.682363735104445e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 294 / dLoss: 6.440042852773331e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 295 / dLoss: 1.64020514148433e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 296 / dLoss: 8.93524156708736e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 297 / dLoss: 4.476339199754875e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 298 / dLoss: 7.260183792823227e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 299 / dLoss: 1.0078585546580143e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 300 / dLoss: 1.3106642654747702e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 301 / dLoss: 7.674454536754638e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 302 / dLoss: 1.1708295460266527e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 303 / dLoss: 4.72681949759135e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 304 / dLoss: 1.8248842025059275e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 305 / dLoss: 3.033863777091028e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 306 / dLoss: 3.051767635042779e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 307 / dLoss: 7.104638825694565e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 308 / dLoss: 1.0192799891228788e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 309 / dLoss: 1.6381176465074532e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 310 / dLoss: 5.5768473430362064e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 311 / dLoss: 1.7638287317822687e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 312 / dLoss: 3.902986009052256e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 313 / dLoss: 4.2475257941987365e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 314 / dLoss: 8.936056474340148e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 315 / dLoss: 2.133762563971686e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 316 / dLoss: 7.262598046509083e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 317 / dLoss: 5.434877039078856e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 318 / dLoss: 1.5019419379314058e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 319 / dLoss: 9.239946848538239e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 320 / dLoss: 4.420397544890875e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 321 / dLoss: 3.1423751352122054e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 322 / dLoss: 1.7534261132823303e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 323 / dLoss: 1.0304488569090609e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 324 / dLoss: 8.222140422731172e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 325 / dLoss: 6.841247341071721e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 326 / dLoss: 6.119349563959986e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 327 / dLoss: 1.2108914233976975e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 328 / dLoss: 2.2410401925299084e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 329 / dLoss: 3.539343197189737e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 330 / dLoss: 4.828086275665555e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 331 / dLoss: 8.461893230560236e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 332 / dLoss: 6.593748366867658e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 333 / dLoss: 9.870982466964051e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 334 / dLoss: 5.205981778999558e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 335 / dLoss: 2.868178626158624e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 336 / dLoss: 3.472557409622823e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 337 / dLoss: 1.950158093677601e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 338 / dLoss: 3.0612782211392187e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 339 / dLoss: 1.2273124411876779e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 340 / dLoss: 1.029886698233895e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 341 / dLoss: 7.971812010509893e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 342 / dLoss: 5.320398031471996e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 343 / dLoss: 1.2301656170166098e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 344 / dLoss: 6.108411525929114e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 345 / dLoss: 7.4936519922630396e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 346 / dLoss: 1.0800656127685215e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 347 / dLoss: 7.246244422276504e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 348 / dLoss: 1.70766215887852e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 349 / dLoss: 1.2706138477369677e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 350 / dLoss: 2.368623654547264e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 351 / dLoss: 5.05744674228481e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 352 / dLoss: 8.233791959355585e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 353 / dLoss: 1.3883847714168951e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 354 / dLoss: 6.291268164204666e-06 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 355 / dLoss: 5.053816948930034e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 356 / dLoss: 5.80244704906363e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 357 / dLoss: 1.0648957868397702e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 358 / dLoss: 8.449427696177736e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 359 / dLoss: 8.350467396667227e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 360 / dLoss: 2.22673884309188e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 361 / dLoss: 9.448383934795856e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 362 / dLoss: 8.63412697071908e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 363 / dLoss: 7.221046871563885e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 364 / dLoss: 9.615260751161259e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 365 / dLoss: 6.407592081814073e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 366 / dLoss: 2.2207643723959336e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 367 / dLoss: 2.1814580577483866e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 368 / dLoss: 1.3159478839952499e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 369 / dLoss: 3.787260993703967e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 370 / dLoss: 5.402971510193311e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 371 / dLoss: 3.4117292670998722e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 372 / dLoss: 8.637580322101712e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 373 / dLoss: 5.226510438660625e-06 / gLoss: 16.117443084716797\n",
      "Epoch: 374 / dLoss: 1.8953465996673913e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 375 / dLoss: 3.6882956919725984e-06 / gLoss: 16.109994888305664\n",
      "Epoch: 376 / dLoss: 4.908764822175726e-06 / gLoss: 16.096044540405273\n",
      "Epoch: 377 / dLoss: 4.424069629749283e-06 / gLoss: 16.103256225585938\n",
      "Epoch: 378 / dLoss: 1.3207179563323734e-06 / gLoss: 16.098838806152344\n",
      "Epoch: 379 / dLoss: 3.6811547943216283e-06 / gLoss: 16.070634841918945\n",
      "Epoch: 380 / dLoss: 4.541634552879259e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 381 / dLoss: 3.988705884694355e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 382 / dLoss: 1.8994620631929138e-06 / gLoss: 16.113767623901367\n",
      "Epoch: 383 / dLoss: 1.119841545005329e-05 / gLoss: 16.082704544067383\n",
      "Epoch: 384 / dLoss: 1.2086671858924092e-06 / gLoss: 16.081445693969727\n",
      "Epoch: 385 / dLoss: 7.849248504498973e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 386 / dLoss: 2.360919552302221e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 387 / dLoss: 2.053663138212869e-06 / gLoss: 15.88399887084961\n",
      "Epoch: 388 / dLoss: 5.367463018046692e-06 / gLoss: 16.04363250732422\n",
      "Epoch: 389 / dLoss: 1.928228812175803e-06 / gLoss: 16.023653030395508\n",
      "Epoch: 390 / dLoss: 0.0010391748510301113 / gLoss: 16.049280166625977\n",
      "Epoch: 391 / dLoss: 0.00017760497576091439 / gLoss: 16.00723648071289\n",
      "Epoch: 392 / dLoss: 1.9970604625996202e-05 / gLoss: 15.704663276672363\n",
      "Epoch: 393 / dLoss: 0.3023967146873474 / gLoss: 15.546194076538086\n",
      "Epoch: 394 / dLoss: 1.616068959236145 / gLoss: 12.615370750427246\n",
      "Epoch: 395 / dLoss: 15.453107833862305 / gLoss: 0.00044242877629585564\n",
      "Epoch: 396 / dLoss: 17.308013916015625 / gLoss: 7.128786364773987e-06\n",
      "Epoch: 397 / dLoss: 15.588562965393066 / gLoss: 5.478330058394931e-05\n",
      "Epoch: 398 / dLoss: 15.931397438049316 / gLoss: 0.0006052961107343435\n",
      "Epoch: 399 / dLoss: 14.999184608459473 / gLoss: 0.0953109934926033\n",
      "Epoch: 400 / dLoss: 2.5403757095336914 / gLoss: 16.118101119995117\n",
      "Epoch: 401 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 402 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 403 / dLoss: 7.020185535111523e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 404 / dLoss: 0.00012799075921066105 / gLoss: 16.118101119995117\n",
      "Epoch: 405 / dLoss: 0.0011736900778487325 / gLoss: 16.118101119995117\n",
      "Epoch: 406 / dLoss: 0.19922545552253723 / gLoss: 16.118101119995117\n",
      "Epoch: 407 / dLoss: 0.22515547275543213 / gLoss: 16.118101119995117\n",
      "Epoch: 408 / dLoss: 0.49557435512542725 / gLoss: 16.118101119995117\n",
      "Epoch: 409 / dLoss: 0.152517169713974 / gLoss: 16.118101119995117\n",
      "Epoch: 410 / dLoss: 0.09938611835241318 / gLoss: 16.118101119995117\n",
      "Epoch: 411 / dLoss: 0.12096786499023438 / gLoss: 16.118101119995117\n",
      "Epoch: 412 / dLoss: 0.007372172083705664 / gLoss: 16.118101119995117\n",
      "Epoch: 413 / dLoss: 0.0072624050080776215 / gLoss: 16.118101119995117\n",
      "Epoch: 414 / dLoss: 0.00532923499122262 / gLoss: 16.118101119995117\n",
      "Epoch: 415 / dLoss: 7.973797551130701e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 416 / dLoss: 4.994094069843413e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 417 / dLoss: 3.111362048002775e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 418 / dLoss: 8.856321073835716e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 419 / dLoss: 9.295910422224551e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 420 / dLoss: 8.761333447182551e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 421 / dLoss: 4.2643867345759645e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 422 / dLoss: 1.5686613551224582e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 423 / dLoss: 2.3828280859561346e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 424 / dLoss: 3.193451902916422e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 425 / dLoss: 9.464723007113207e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 426 / dLoss: 2.6689303922466934e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 427 / dLoss: 2.692772227419482e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 428 / dLoss: 6.030700205883477e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 429 / dLoss: 6.2279718804347795e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 430 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 431 / dLoss: 8.55796315590851e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 432 / dLoss: 5.25581583588064e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 433 / dLoss: 5.630235591524979e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 434 / dLoss: 5.76965658183326e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 435 / dLoss: 2.4781957108643837e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 436 / dLoss: 4.957785790793423e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 437 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 438 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 439 / dLoss: 9.840394341154024e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 440 / dLoss: 1.4663466572528705e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 441 / dLoss: 5.099513600725913e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 442 / dLoss: 9.402815521752927e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 443 / dLoss: 1.0122831554326694e-05 / gLoss: 16.118101119995117\n",
      "Epoch: 444 / dLoss: 2.33514427350201e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 445 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 446 / dLoss: 4.7627063395339064e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 447 / dLoss: 4.7495886974502355e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 448 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 449 / dLoss: 4.725737653643591e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 450 / dLoss: 4.90810998599045e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 451 / dLoss: 8.671655450598337e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 452 / dLoss: 7.647327947779559e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 453 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 454 / dLoss: 3.658377067949914e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 455 / dLoss: 8.461875950160902e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 456 / dLoss: 2.698473281270708e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 457 / dLoss: 2.4588059659436112e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 458 / dLoss: 2.351476041440037e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 459 / dLoss: 4.042600721732015e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 460 / dLoss: 2.2159349555295194e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 461 / dLoss: 2.8477467139964574e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 462 / dLoss: 3.4080312616424635e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 463 / dLoss: 3.1758011118654395e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 464 / dLoss: 1.5615964912285563e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 465 / dLoss: 4.035342044517165e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 466 / dLoss: 1.5520405440838658e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 467 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 468 / dLoss: 1.2921499319418217e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 469 / dLoss: 2.573563619989727e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 470 / dLoss: 2.5616424181862385e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 471 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 472 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 473 / dLoss: 1.1383555147403968e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 474 / dLoss: 2.513958747840661e-07 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475 / dLoss: 2.513958747840661e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 476 / dLoss: 2.502037830254267e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 477 / dLoss: 3.1219269658322446e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 478 / dLoss: 2.788140704979014e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 479 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 480 / dLoss: 1.0584783467493253e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 481 / dLoss: 2.4901169126678724e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 482 / dLoss: 2.7642988698062254e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 483 / dLoss: 1.8548272464613547e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 484 / dLoss: 1.0239047014692915e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 485 / dLoss: 1.0656265203579096e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 486 / dLoss: 9.964838909581886e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 487 / dLoss: 1.0596638730930863e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 488 / dLoss: 9.917134775605518e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 489 / dLoss: 9.750229992278037e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 490 / dLoss: 2.4305120405188063e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 491 / dLoss: 9.452189146941237e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 492 / dLoss: 9.321050242760975e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 493 / dLoss: 2.250603756692726e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 494 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 495 / dLoss: 8.641523550068086e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 496 / dLoss: 2.394749003542529e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 497 / dLoss: 1.4816745306234225e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 498 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 499 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 500 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 501 / dLoss: 2.3828280859561346e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 502 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 503 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 504 / dLoss: 8.057352260948392e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 505 / dLoss: 7.830852837287239e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 506 / dLoss: 1.3731864783039782e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 507 / dLoss: 1.3564966820922564e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 508 / dLoss: 7.592419706270448e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 509 / dLoss: 7.99772521986597e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 510 / dLoss: 7.401675361506932e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 511 / dLoss: 7.473198024854355e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 512 / dLoss: 1.2253613022039644e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 513 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 514 / dLoss: 7.044029644021066e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 515 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 516 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 517 / dLoss: 7.008257512097771e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 518 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 519 / dLoss: 1.1478708756840206e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 520 / dLoss: 6.710228035444743e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 521 / dLoss: 6.650621457993111e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 522 / dLoss: 2.3232233559156157e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 523 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 524 / dLoss: 6.638692298110982e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 525 / dLoss: 6.734059070367948e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 526 / dLoss: 2.3113024383292213e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 527 / dLoss: 2.4305120405188063e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 528 / dLoss: 2.4305120405188063e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 529 / dLoss: 2.3113024383292213e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 530 / dLoss: 6.316822123153543e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 531 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 532 / dLoss: 6.269132200031891e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 533 / dLoss: 6.3525811810905e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 534 / dLoss: 6.209527327882824e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 535 / dLoss: 6.53139068163e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 536 / dLoss: 2.299381520742827e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 537 / dLoss: 6.102235943217238e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 538 / dLoss: 6.066470064070018e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 539 / dLoss: 6.245285248951404e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 540 / dLoss: 2.4066699211289233e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 541 / dLoss: 9.833548801907455e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 542 / dLoss: 2.299381520742827e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 543 / dLoss: 2.299381520742827e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 544 / dLoss: 5.959173563496734e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 545 / dLoss: 9.463994388170249e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 546 / dLoss: 2.2874607452649798e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 547 / dLoss: 5.756513132837426e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 548 / dLoss: 5.720752369597903e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 549 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 550 / dLoss: 2.2874607452649798e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 551 / dLoss: 5.732669023927883e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 552 / dLoss: 9.010983603729983e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 553 / dLoss: 5.67306301491044e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 554 / dLoss: 5.541929795072065e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 555 / dLoss: 5.589612896983454e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 556 / dLoss: 5.637293725158088e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 557 / dLoss: 5.518084549294144e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 558 / dLoss: 8.605655352766917e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 559 / dLoss: 5.530004614229256e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 560 / dLoss: 5.398870825956692e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 561 / dLoss: 5.279660513224371e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 562 / dLoss: 8.2957046743104e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 563 / dLoss: 5.291580009725294e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 564 / dLoss: 8.152645705195027e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 565 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 566 / dLoss: 8.08112076811085e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 567 / dLoss: 5.136603817845753e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 568 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 569 / dLoss: 2.33514427350201e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 570 / dLoss: 7.818851486263156e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 571 / dLoss: 5.017392368245055e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 572 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 573 / dLoss: 4.898182055512734e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 574 / dLoss: 4.874339083471568e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 575 / dLoss: 2.4066699211289233e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 576 / dLoss: 1.0131537919733091e-06 / gLoss: 16.118101119995117\n",
      "Epoch: 577 / dLoss: 2.2516978503972496e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 578 / dLoss: 7.485052719857777e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 579 / dLoss: 2.3113024383292213e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 580 / dLoss: 4.790888397110393e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 581 / dLoss: 4.778966058438527e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 582 / dLoss: 7.19894728717918e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 583 / dLoss: 4.731281251224573e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 584 / dLoss: 4.6478339754685294e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 585 / dLoss: 2.2516978503972496e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 586 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 587 / dLoss: 2.2516978503972496e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 588 / dLoss: 7.020126986390096e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 589 / dLoss: 4.6120703700580634e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 590 / dLoss: 4.6597529035352636e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 591 / dLoss: 2.430511756301712e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 592 / dLoss: 4.623989866558986e-07 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 593 / dLoss: 9.094388246921881e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 594 / dLoss: 4.469016516850388e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 595 / dLoss: 4.4451746816775994e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 596 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 597 / dLoss: 4.457094746612711e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 598 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 599 / dLoss: 2.2874606031564326e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 600 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 601 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 602 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 603 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 604 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 605 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 606 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 607 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 608 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 609 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 610 / dLoss: 4.325962663642713e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 611 / dLoss: 4.325962663642713e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 612 / dLoss: 2.2874606031564326e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 613 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 614 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 615 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 616 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 617 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 618 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 619 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 620 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 621 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 622 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 623 / dLoss: 2.2874606031564326e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 624 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 625 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 626 / dLoss: 4.385565830489213e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 627 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 628 / dLoss: 4.278277856428758e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 629 / dLoss: 2.2874606031564326e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 630 / dLoss: 4.278277856428758e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 631 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 632 / dLoss: 4.3617239953164244e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 633 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 634 / dLoss: 4.3021191231673583e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 635 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 636 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 637 / dLoss: 4.32595982147177e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 638 / dLoss: 6.340618483591243e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 639 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 640 / dLoss: 6.364460318764031e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 641 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 642 / dLoss: 8.164537348420708e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 643 / dLoss: 4.1590658383938717e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 644 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 645 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 646 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 647 / dLoss: 8.021481789910467e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 648 / dLoss: 9.821558251132956e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 649 / dLoss: 4.111381031179917e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 650 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 651 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 652 / dLoss: 4.0279326185554964e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 653 / dLoss: 4.087536922270374e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 654 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 655 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 656 / dLoss: 5.768405912931485e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 657 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 658 / dLoss: 4.0040896465143305e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 659 / dLoss: 7.520794724769075e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 660 / dLoss: 3.980247811341542e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 661 / dLoss: 3.968327177972242e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 662 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 663 / dLoss: 5.661112254529144e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 664 / dLoss: 3.932563004127587e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 665 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 666 / dLoss: 3.908721737388987e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 667 / dLoss: 3.861037498609221e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 668 / dLoss: 5.541902510231012e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 669 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 670 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 671 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 672 / dLoss: 3.88487933378201e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 673 / dLoss: 7.091636575751181e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 674 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 675 / dLoss: 2.2278560152244609e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 676 / dLoss: 5.363086756915436e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 677 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 678 / dLoss: 3.789510287788289e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 679 / dLoss: 6.924739182068151e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 680 / dLoss: 3.765667884181312e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 681 / dLoss: 6.805530574638397e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 682 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 683 / dLoss: 5.243874170446361e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 684 / dLoss: 3.717983645401546e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 685 / dLoss: 3.68222003999108e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 686 / dLoss: 3.67029940662178e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 687 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 688 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 689 / dLoss: 3.69414067336038e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 690 / dLoss: 2.2397769328108552e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 691 / dLoss: 5.076979050500086e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 692 / dLoss: 3.67029940662178e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 693 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 694 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 695 / dLoss: 2.263618767983644e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 696 / dLoss: 6.412133757294214e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 697 / dLoss: 3.610693966038525e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 698 / dLoss: 3.6583776363841025e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 699 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 700 / dLoss: 4.95776646403101e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 701 / dLoss: 3.563009727258759e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 702 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 703 / dLoss: 2.2159349555295194e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 704 / dLoss: 4.933925765726599e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 705 / dLoss: 3.539167323651782e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 706 / dLoss: 3.527246121848293e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 707 / dLoss: 3.527246121848293e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 708 / dLoss: 2.2159349555295194e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 709 / dLoss: 2.1920931203567307e-07 / gLoss: 16.118101119995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710 / dLoss: 4.814715452994278e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 711 / dLoss: 3.598771627366659e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 712 / dLoss: 3.491482516437827e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 713 / dLoss: 2.2159349555295194e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 714 / dLoss: 2.2159349555295194e-07 / gLoss: 16.118101119995117\n",
      "Epoch: 715 / dLoss: 7.389652409983682e-07 / gLoss: 16.118101119995117\n"
     ]
    }
   ],
   "source": [
    "regcgan = reg_cgan_model.RegCGAN(exp_config)\n",
    "d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = regcgan.train(X_train, y_train,\n",
    "                                                                              epochs=exp_config.training.n_epochs,\n",
    "                                                                              batch_size=exp_config.training.batch_size,\n",
    "                                                                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_training_curve(d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true, fig_dir, exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pairs of virtual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "X_cvt = np.load(f\"{fig_dir}/{basename(fig_dir)}_cvt_samples.npy\")\n",
    "X_cvt_scaled = X_scaler.transform(X_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ypred_recgan_cvt = regcgan.predict(X_cvt_scaled)\n",
    "ypred_gp_cvt, cov_cvt = gpr.predict(X_cvt_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% using inverse normalization to transform the output to its true range.\n"
    }
   },
   "outputs": [],
   "source": [
    "ypred_recgan_cvt = y_scaler.inverse_transform(ypred_recgan_cvt)\n",
    "ypred_gp_cvt = y_scaler.inverse_transform(ypred_gp_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_cvt_paird = np.c_[X_cvt, ypred_recgan_cvt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% save pairs of generated virtual samples, which will used as a part of training samples to train MLP soft sensor.\n"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "np.save(f\"{fig_dir}/{basename(fig_dir)}_CVT_samples_paired.npy\", X_cvt_paird)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (RegCGAN)",
   "language": "python",
   "name": "pycharm-a0f56720"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}