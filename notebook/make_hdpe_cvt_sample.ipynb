{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import dataset, metrics, plotting, config, network\n",
    "from models import cgan_model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "importlib.reload(network)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(config)\n",
    "importlib.reload(cgan_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_config = config.DatasetConfig(scenario=\"hdpe\")\n",
    "\n",
    "assert(dataset_config.scenario == \"magical_sinus\"\n",
    "      or dataset_config.scenario == \"hdpe\")\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_config = config.Config(\n",
    "    model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0001,\n",
    "                             optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=5),\n",
    "    training=config.TrainingConfig(n_epochs=10000, batch_size=100, n_samples=500),\n",
    "    dataset=dataset_config,\n",
    "    run=config.RunConfig(save_fig=1)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(exp_config.model.random_seed)\n",
    "random.seed(exp_config.model.random_seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(exp_config.model.random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = dataset.get_dataset(scenario=exp_config.dataset.scenario,\n",
    "                                                                         seed=exp_config.model.random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% max-min nomalization, which is a prerequisite in compution of unanchored_L2_discrepancy.\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding sparse regions using Local Outlier Factor (LOF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "X = X_train_scaled\n",
    "clf = LocalOutlierFactor(n_neighbors=40)\n",
    "clf.fit(X)\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "mean_scores = np.mean(X_scores)\n",
    "mask = X_scores > mean_scores\n",
    "\n",
    "X_outliers = X[mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CVT sampling and discrepancy evaluating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from idaes.surrogate.pysmo import sampling as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from diversipy import unanchored_L2_discrepancy\n",
    "\n",
    "assert len(X_outliers) !=0, \"No sparse regions in the input space has been found.\"\n",
    "\n",
    "min_n_sampling, max_n_sampling, interval = 60, 500, 60\n",
    "\n",
    "minimum, maximum = np.amin(X_outliers, axis=0).tolist(), np.amax(X_outliers, axis=0).tolist()\n",
    "bounds = [minimum, maximum]\n",
    "\n",
    "X_discrepancy = unanchored_L2_discrepancy(X_outliers)\n",
    "X_CVT_discrepancy_list, X_full_discrepancy_list, CVT_dict = [], [], {}\n",
    "i = 0\n",
    "for n_sampling in range(min_n_sampling, max_n_sampling, interval):\n",
    "    space_init = sp.CVTSampling(bounds, sampling_type=\"creation\", number_of_samples=n_sampling)\n",
    "    X_CVT = space_init.sample_points()\n",
    "    CVT_dict[f\"num_sampling_{n_sampling}\"] = X_CVT\n",
    "    X_CVT_discrepancy = unanchored_L2_discrepancy(X_CVT)\n",
    "    X_CVT_discrepancy_list.append(X_CVT_discrepancy)\n",
    "\n",
    "    X_full = np.r_[X, X_CVT]\n",
    "    X_full_discrepancy = unanchored_L2_discrepancy(X_full)\n",
    "    X_full_discrepancy_list.append(X_full_discrepancy)\n",
    "    print(f\"Discrepancy values: {X_discrepancy:.2e} for original data; \"\n",
    "          f\"{X_CVT_discrepancy:.2e} for {n_sampling} CVT samples; \"\n",
    "          f\"{X_full_discrepancy:.2e} for full data.\")\n",
    "\n",
    "best_n_sampling = np.arange(min_n_sampling, max_n_sampling, interval)[np.argmin(np.array(X_full_discrepancy_list))]\n",
    "best_CVT = CVT_dict[f\"num_sampling_{best_n_sampling}\"]\n",
    "print(f\"The  optimal value for n_sampling in CVT sampling is {best_n_sampling}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_discrepancy = unanchored_L2_discrepancy(X_outliers)\n",
    "plotting.plot_cvt_discrepancy(min_n_sampling, max_n_sampling, interval,\n",
    "                              X_full_discrepancy_list, fig_dir,\n",
    "                              title=f\"Discrepancy baseline = {X_discrepancy:2.2e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  explore the optimal value for n_sampling\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampling_key = f\"num_sampling_{best_n_sampling}\"\n",
    "X_CVT = CVT_dict[sampling_key]\n",
    "\n",
    "# save CVT samples to .npy file\n",
    "from os.path import basename\n",
    "np.save(f\"{fig_dir}/{basename(fig_dir)}_CVT_samples.npy\", X_scaler.inverse_transform(X_CVT))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Plot Voronoi tessellation digram for CVT samples the size of best_n_sampling.\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ganRegression)",
   "language": "python",
   "name": "pycharm-25d74700"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}